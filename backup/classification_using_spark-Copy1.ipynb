{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.feature import IDF\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from nltk.stem import PorterStemmer\n",
    "import string, timeit\n",
    "import matplotlib.pyplot as pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation)\n",
    "stem_porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words_set = ['out', '', 'we', 'was', 'how', 'myself', 'for', 'they', 'about', 'then', 'both', 'so', \n",
    "                  'don', 'as', 'any', 'after', 'you', 'why', 'been', 'where', 'by', 'yourself', 'a', 'did', \n",
    "                  'their', 'doing', 'be', \n",
    "                  'further', 'ours', 'now', 'am', 'her', 'yourselves', 'that', 'my', 'what', 'to', 'not', \n",
    "                  'own', 'there', \n",
    "                  'this', 'each', 'all', 'more', 'me', 'which', 'himself', 'nor', 'other', 'who', 'same', \n",
    "                  'at', 'such', \n",
    "                  't', 'up', 'than', 'can', 'too', 'these', 'while', 'ourselves', 'before', 'i', 'he', 'our', \n",
    "                  'its', \n",
    "                  'but', 'with', 'those', 'because', 'the', 'it', 'hers', 'just', 'between', 'over', 'had', 'does', \n",
    "                  'have', 'and', 'or', 'some', 'only', 'when', 'below', 'in', 'if', 'theirs', 'again', 'his', \n",
    "                  'whom', \n",
    "                  'above', 'should', 'itself', 'themselves', 'until', 'are', 'she', 'no', 'from', 'into', \n",
    "                  'will', \n",
    "                  'your', 'few', 'herself', 'of', 'has', 'down', 'were', 'once', 'having', 'them', 'under', 'him', \n",
    "                  'do', 'on', 'an', 'yours', 'being', 'off', 'very', 'through', 'most', 'against', 'here', \n",
    "                  'is', 's', 'during']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_csv_file = sc.textFile(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip_punctuations(words_array):\n",
    "    cleaned_words = []\n",
    "    for word in words_array:\n",
    "        new_word = ''.join(ch for ch in word if ch not in exclude)\n",
    "        # new_word = stem_porter.stem(new_word)\n",
    "        # new_word = word.strip('.,\"')\n",
    "        if len(new_word) != 0:\n",
    "           cleaned_words.append(new_word)\n",
    "    return cleaned_words\n",
    "\n",
    "\n",
    "def replace_URL(words_array):\n",
    "    new_words_array = []\n",
    "    for single_word in words_array:\n",
    "        new_word = single_word\n",
    "        if single_word.startswith(\"www.\") or single_word.startswith(\"http://\") or single_word.startswith(\"https://\"):\n",
    "            new_word = \"URL\"\n",
    "        \n",
    "        new_words_array.append(new_word)\n",
    "    return new_words_array\n",
    "\n",
    "\n",
    "def replace_AT_USER(words_array):\n",
    "    new_words_array = []\n",
    "    for single_word in words_array:\n",
    "        new_word = single_word\n",
    "        if single_word.startswith(\"@\"):\n",
    "            new_word = \"ATUSER\"\n",
    "        \n",
    "        new_words_array.append(new_word)\n",
    "    return new_words_array\n",
    "\n",
    "\n",
    "def clean_numeric_words(words_array):\n",
    "    new_words_array = []\n",
    "    for single_word in words_array:\n",
    "        if len(single_word) >= 2 and single_word[0].isalpha() and single_word[1].isalpha():\n",
    "            new_words_array.append(single_word)\n",
    "    return new_words_array\n",
    "\n",
    "\n",
    "def remove_stop_words(words_array):\n",
    "    new_words_array = []\n",
    "    for single_word in words_array:\n",
    "        if single_word not in stop_words_set:\n",
    "            new_words_array.append(single_word)\n",
    "    return new_words_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_bag_of_words(bag_of_words):\n",
    "    # clean the given bag of words.\n",
    "    new_words = bag_of_words.lower().split()\n",
    "    new_words = replace_AT_USER(new_words)\n",
    "    new_words = replace_URL(new_words)\n",
    "    new_words = strip_punctuations(new_words)\n",
    "    new_words = clean_numeric_words(new_words)\n",
    "    # new_words = remove_stop_words(new_words)\n",
    "    # print(type(cleaned_words))\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_bag_of_words(tweet_text):\n",
    "    # create bag of words in this module. \n",
    "    bag_of_cleaned_words = clean_bag_of_words(tweet_text)\n",
    "    return bag_of_cleaned_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Tweets and Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_clean_tweet_words(single_line):\n",
    "    filtered_line = single_line.split(\",\", 5)\n",
    "    labeled_point_label = float(filtered_line[0][1])\n",
    "    tweet_text = filtered_line[-1]\n",
    "    bag_of_cleaned_words = create_bag_of_words(tweet_text)\n",
    "    return bag_of_cleaned_words \n",
    "\n",
    "\n",
    "def extract_polarity(single_line):\n",
    "    filtered_line = single_line.split(\",\", 5)\n",
    "    labeled_point_label = float(filtered_line[0][1])\n",
    "    return labeled_point_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_clean_words = train_csv_file.map(extract_clean_tweet_words)\n",
    "train_polarity_rdd = train_csv_file.map(extract_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_tf_idf(documents):\n",
    "    hashingTF = HashingTF()\n",
    "    tf = hashingTF.transform(documents)\n",
    "    tf.cache()\n",
    "    idf = IDF().fit(tf)\n",
    "    tfidf = idf.transform(tf)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_idf = apply_tf_idf(train_clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_clean_words_list = train_data_idf.collect()\n",
    "train_polarity_list = train_polarity_rdd.collect()\n",
    "\n",
    "train_data_idf_list = []\n",
    "for i in range(len(train_clean_words_list)):\n",
    "    train_data_idf_list.append(LabeledPoint(train_polarity_list[i], train_clean_words_list[i]))\n",
    "\n",
    "train_data = sc.parallelize(train_data_idf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for single_line in train_csv_file.take(100):\n",
    "#     filtered_line = single_line.split(\",\", 5)\n",
    "#     labeled_point_label = filtered_line[0][1]\n",
    "#     tweet_text = filtered_line[-1]\n",
    "#     bag_of_cleaned_words = create_bag_of_words(tweet_text)\n",
    "#     hashingTF = HashingTF()\n",
    "#     hashing_tf_features = hashingTF.transform(bag_of_cleaned_words)\n",
    "#     print(bag_of_cleaned_words)\n",
    "#     # print(hashing_tf_features)\n",
    "#     # print(labeled_point_label)\n",
    "#     # print(hashing_tf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_labeled_point(single_line):\n",
    "    filtered_line = single_line.split(\",\", 5)\n",
    "    labeled_point_label = float(filtered_line[0][1])\n",
    "    tweet_text = filtered_line[-1]\n",
    "    bag_of_cleaned_words = create_bag_of_words(tweet_text)\n",
    "    hashingTF = HashingTF()\n",
    "    hashing_tf_features = hashingTF.transform(bag_of_cleaned_words)\n",
    "    return LabeledPoint(labeled_point_label, hashing_tf_features)\n",
    "\n",
    "\n",
    "def calculate_accuracy_count(predictionAndLabel, total_count):\n",
    "    accuracy_count = 0\n",
    "    for x in predictionAndLabel.collect():\n",
    "        if x[0] == x[1]: \n",
    "            accuracy_count += 1\n",
    "    \n",
    "    accuracy = 1.0 * accuracy_count / total_count\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on train data itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.3 s, sys: 14.8 s, total: 1min 13s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%time naive_bayes_model = NaiveBayes.train(train_data, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy on Training Data\n",
      "0.9248375\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabel = train_data.map(lambda p: (float(naive_bayes_model.predict(p.features)), p.label))\n",
    "naive_bayes_training_data_accuracy = calculate_accuracy_count(predictionAndLabel, train_data.count())\n",
    "print(\"Naive Bayes Accuracy on Training Data\")\n",
    "print(naive_bayes_training_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.4 s, sys: 7.25 s, total: 35.6 s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%time logistic_regression_model = LogisticRegressionWithLBFGS.train(train_data, iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9695125\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabel = train_data.map(lambda p: (float(logistic_regression_model.predict(p.features)), p.label))\n",
    "logistic_regression_training_data_accuracy = calculate_accuracy_count(predictionAndLabel, train_data.count())\n",
    "print(\"Logistic Regression Accuracy on Training Data\")\n",
    "print(logistic_regression_training_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on main testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57 s, sys: 14.4 s, total: 1min 11s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%time naive_bayes_model = NaiveBayes.train(train_data, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_csv_file = sc.textFile(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = test_csv_file.map(extract_labeled_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy on Testing Data\n",
      "0.7604456824512534\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabel = test_data.map(lambda p: (float(naive_bayes_model.predict(p.features)), p.label))\n",
    "naive_bayes_testing_data_accuracy = calculate_accuracy_count(predictionAndLabel, test_data.count())\n",
    "print(\"Naive Bayes Accuracy on Testing Data\")\n",
    "print(naive_bayes_testing_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall, F-1 Score and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Precision\n",
      "0.7604456824512534\n",
      "Naive Bayes Recall\n",
      "0.7604456824512534\n",
      "Naive Bayes F-1 Score\n",
      "0.7604456824512534\n",
      "Naive Bayes Confusion Matrix\n",
      "DenseMatrix([[ 136.,   41.],\n",
      "             [  45.,  137.]])\n"
     ]
    }
   ],
   "source": [
    "metrics = MulticlassMetrics(predictionAndLabel)\n",
    "naive_bayes_precision = metrics.precision()\n",
    "print(\"Naive Bayes Precision\")\n",
    "print(naive_bayes_precision)\n",
    "naive_bayes_recall = metrics.recall()\n",
    "print(\"Naive Bayes Recall\")\n",
    "print(naive_bayes_recall)\n",
    "naive_bayes_f1_score = metrics.fMeasure()\n",
    "print(\"Naive Bayes F-1 Score\")\n",
    "print(naive_bayes_f1_score)\n",
    "naive_bayes_confusion_matric = metrics.confusionMatrix()\n",
    "print(\"Naive Bayes Confusion Matrix\")\n",
    "print(naive_bayes_confusion_matric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.1 s, sys: 7.15 s, total: 35.2 s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%time logistic_regression_model = LogisticRegressionWithLBFGS.train(train_data, iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy on Testing Data\n",
      "0.7381615598885793\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabel = test_data.map(lambda p: (float(logistic_regression_model.predict(p.features)), p.label))\n",
    "logistic_regression_testing_data_accuracy = calculate_accuracy_count(predictionAndLabel, test_data.count())\n",
    "print(\"Logistic Regression Accuracy on Testing Data\")\n",
    "print(logistic_regression_testing_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall, F-1 Score and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Precision\n",
      "0.7381615598885793\n",
      "Logistic Regression Recall\n",
      "0.7381615598885793\n",
      "Logistic Regression F-1 Score\n",
      "0.7381615598885793\n",
      "Logistic Regression Confusion Matrix\n",
      "DenseMatrix([[ 122.,   55.],\n",
      "             [  39.,  143.]])\n"
     ]
    }
   ],
   "source": [
    "metrics = MulticlassMetrics(predictionAndLabel)\n",
    "logistic_regression_precision = metrics.precision()\n",
    "print(\"Logistic Regression Precision\")\n",
    "print(logistic_regression_precision)\n",
    "logistic_regression_recall = metrics.recall()\n",
    "print(\"Logistic Regression Recall\")\n",
    "print(logistic_regression_recall)\n",
    "logistic_regression_f1_score = metrics.fMeasure()\n",
    "print(\"Logistic Regression F-1 Score\")\n",
    "print(logistic_regression_f1_score)\n",
    "logistic_regression_confusion_matric = metrics.confusionMatrix()\n",
    "print(\"Logistic Regression Confusion Matrix\")\n",
    "print(logistic_regression_confusion_matric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing by doing random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, test = train_data.randomSplit([0.8, 0.2], seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying NaiveBayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.1 s, sys: 14.5 s, total: 1min 11s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%time naive_bayes_model = NaiveBayes.train(training, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7128749767095212\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabel = test.map(lambda p: (float(naive_bayes_model.predict(p.features)), p.label))\n",
    "naive_bayes_split_data_accuracy = calculate_accuracy_count(predictionAndLabel, test.count())\n",
    "print(naive_bayes_split_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.3 s, sys: 7.3 s, total: 35.6 s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%time logistic_regression_model = LogisticRegressionWithLBFGS.train(training, iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7324389789454071\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabel = test.map(lambda p: (float(logistic_regression_model.predict(p.features)), p.label))\n",
    "logistic_regression_split_data_accuracy = calculate_accuracy_count(predictionAndLabel, test.count())\n",
    "print(logistic_regression_split_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing by K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_rdd_list = train_data.randomSplit([0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7117267652341983\n"
     ]
    }
   ],
   "source": [
    "def calculate_naive_bayes_average_accuracy():\n",
    "    avg = 0\n",
    "    length_rdd_list = len(split_rdd_list)\n",
    "    for i in range(length_rdd_list):\n",
    "        training_k_fold_data = None\n",
    "        test_k_fold_data = None\n",
    "        for j in range(length_rdd_list):\n",
    "            if j != i:\n",
    "                if training_k_fold_data is None:\n",
    "                    training_k_fold_data = split_rdd_list[j]\n",
    "                else:\n",
    "                    training_k_fold_data = training_k_fold_data.union(split_rdd_list[j])\n",
    "            else:\n",
    "                test_k_fold_data = split_rdd_list[i]\n",
    "\n",
    "        naive_bayes_model = NaiveBayes.train(training_k_fold_data, 1.0)\n",
    "        predictionAndLabel = test_k_fold_data.map(lambda p: (float(naive_bayes_model.predict(p.features)), p.label))\n",
    "        accuracy = calculate_accuracy_count(predictionAndLabel, test_k_fold_data.count())\n",
    "        avg += accuracy\n",
    "    return avg/length_rdd_list\n",
    "\n",
    "    \n",
    "naive_bayes_k_fold_accuracy = calculate_naive_bayes_average_accuracy()\n",
    "print(naive_bayes_k_fold_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_rdd_list = train_data.randomSplit([0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7304395160784233\n"
     ]
    }
   ],
   "source": [
    "def calculate_logistic_regression_average_accuracy():\n",
    "    avg = 0\n",
    "    length_rdd_list = len(split_rdd_list)\n",
    "    for i in range(length_rdd_list):\n",
    "        training_k_fold_data = None\n",
    "        test_k_fold_data = None\n",
    "        for j in range(length_rdd_list):\n",
    "            if j != i:\n",
    "                if training_k_fold_data is None:\n",
    "                    training_k_fold_data = split_rdd_list[j]\n",
    "                else:\n",
    "                    training_k_fold_data = training_k_fold_data.union(split_rdd_list[j])\n",
    "            else:\n",
    "                test_k_fold_data = split_rdd_list[i]\n",
    "\n",
    "        logistic_regression_model = LogisticRegressionWithLBFGS.train(training_k_fold_data, iterations=100)\n",
    "        predictionAndLabel = test_k_fold_data.map(lambda p: (float(logistic_regression_model.predict(p.features)), p.label))\n",
    "        accuracy = calculate_accuracy_count(predictionAndLabel, test_k_fold_data.count())\n",
    "        avg += accuracy\n",
    "    return avg/length_rdd_list\n",
    "\n",
    "\n",
    "logistic_regression_k_fold_accuracy = calculate_logistic_regression_average_accuracy()\n",
    "print(logistic_regression_k_fold_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
